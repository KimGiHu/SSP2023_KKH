{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 : \n",
    "# Isolated Digit Recognition in Noisy Env."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages, define analysis parameters and draw parameters, audio file preparation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary pacakages\n",
    "# strange issue: keep the import order to prevent matplotlib error\n",
    "#  import matplotlib -> librosa -> pyplot -> librosa.display\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import librosa\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "#from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "\n",
    "# display wav files\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add '/' if path is not a null string\n",
    "def addpath(path, file):\n",
    "    if len(path) == 0: \n",
    "        return file\n",
    "    else:\n",
    "        return path + '/' + file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ts : Shift length in seconds, default 0.01 sec = 10ms\n",
    "# Tf : Frame length in seconds, default 0.02 sec = 20ms\n",
    "# Fs : navtive sampling frequency, set the sampling rate value as 16000\n",
    "Fs = 16000\n",
    "Ts = 0.01\n",
    "Tf = 0.02\n",
    "\n",
    "# to set the parameter for rawing the spectrum\n",
    "cmap_plot = plt.cm.bone_r # default colormap for spectrogram, gray, reversed\n",
    "FIG_SIZE = (8,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw spectrogram\n",
    "from utils.gjdrawspectrogram3 import drawspectrogram3\n",
    "\n",
    "# linear phase FIR filter design from magnitudes of the frequency components\n",
    "from utils.gjfiroverlappadd import getLPHFIRFFT\n",
    "\n",
    "# trapezoidal overlap add for FIR filtering\n",
    "from utils.gjfiroverlappadd import firoverlapadd\n",
    "\n",
    "# save audio in wav format\n",
    "import utils.gjwavfile as wav"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - - - - - - "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load Speech and Noise\n",
    "오디오 파일이 16kHz, mono인지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size 함수 대신, len 사용.\n",
    "def check_audio_file(file, defFs, checkMono):\n",
    "    signal, Fs = librosa.load(file, sr=None, mono=False)\n",
    "    if defFs != Fs:\n",
    "        print('sampling rate mismatch, %d != %d for file %s'%(defFs, Fs, file))\n",
    "        return False\n",
    "    elif checkMono == True:\n",
    "        if signal.ndim != 1:\n",
    "            print('not mono file %s, shape='%(file), signal.shape)\n",
    "            return False\n",
    "        return True\n",
    "    elif len(signal) <= 0:\n",
    "        print('wrong audio file %s, shape='%(file), signal.shape)\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def convert_audio_file(file, forceFs, forceMono):\n",
    "    signal, Fs = librosa.load(file, sr=None, mono=False)\n",
    "    changed = False\n",
    "    if forceFs != Fs:\n",
    "        print('sampling rate mismatch, %d != %d for file %s'%(forceFs, Fs, file))\n",
    "        signal, Fs = librosa.load(file, sr=forceFs, mono=False)\n",
    "        changed = True\n",
    "    elif forceMono == True:\n",
    "        if signal.ndim != 1:\n",
    "            print('not mono file %s, shape='%(file), signal.shape)\n",
    "            signal, Fs = librosa.load(file, sr=forceFs, mono=True)\n",
    "            changed = True\n",
    "    elif len(signal) <= 0:\n",
    "        print('wrong audio file %s, shape='%(file), signal.shape)\n",
    "        return False\n",
    "    if changed == True:\n",
    "        wav.writewav(file, Fs, signal, maxval=1.0)\n",
    "        print('updating', file)\n",
    "    return changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11jeonghy: false 0 / 100\n",
      "\n",
      "YouYeNa: false 0 / 100\n",
      "\n",
      "Dandyst: false 0 / 100\n",
      "\n",
      "deokkyukwon: false 0 / 100\n",
      "\n",
      "InkooJeon: false 0 / 100\n",
      "\n",
      "son: false 0 / 100\n",
      "\n",
      "ohjihyeon: false 0 / 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainroot = current_path+'/audio/segmented_all/segmented-train/segmented-train'\n",
    "labels_train = {'11jeonghy', \n",
    "                'Dandyst', \n",
    "                'InkooJeon',\n",
    "                'YouYeNa',\n",
    "                'deokkyukwon',\n",
    "                'ohjihyeon',\n",
    "                'son',\n",
    "               }\n",
    "\n",
    "# check, 파일 로드가 제대로 되었는지 false를 통해서 확인함.\n",
    "# 0일 경우, 파일로딩이 제대로 이루어졌음을 알 수 있음.\n",
    "Fs = 16000\n",
    "for subname in labels_train:\n",
    "    num_files = 0\n",
    "    num_false_files = 0\n",
    "    for w in range(10):\n",
    "        for trial in range(10):\n",
    "            basename = '%d/kdigits%d-%d.wav'%(w,trial,w)\n",
    "            file = addpath(trainroot, addpath(subname, basename))\n",
    "            num_files += 1\n",
    "            if check_audio_file(file, Fs, True) == False:\n",
    "                num_false_files += 1\n",
    "    print('%s: false %d / %d\\n'%(subname, num_false_files, num_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chlee: false 0 / 100\n",
      "\n",
      "do: false 0 / 100\n",
      "\n",
      "kyeong: false 0 / 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valroot =  current_path+'/audio/segmented_all/segmented-val'\n",
    "valclean = addpath(valroot, 'org')\n",
    "labels_val = {\n",
    "                'chlee',\n",
    "                'do',\n",
    "                'kyeong',\n",
    "               }\n",
    "\n",
    "# check\n",
    "Fs = 16000\n",
    "for subname in labels_val:\n",
    "    num_files = 0\n",
    "    num_false_files = 0\n",
    "    for w in range(10):\n",
    "        for trial in range(10):\n",
    "            basename = '%d/kdigits%d-%d.wav'%(w,trial,w)\n",
    "            file = addpath(valclean, addpath(subname, basename))\n",
    "            num_files += 1\n",
    "            if check_audio_file(file, Fs, True) == False:\n",
    "                num_false_files += 1\n",
    "    print('%s: false %d / %d\\n'%(subname, num_false_files, num_files))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - - - \n",
    "### HMM training and test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from scikits.talkbox.features import mfcc\n",
    "#librosa.feature.mfcc(*, y=None, sr=22050, S=None, n_mfcc=20, dct_type=2, norm='ortho', lifter=0, **kwargs)[source]\n",
    "from librosa.feature import mfcc\n",
    "from scipy.io import wavfile\n",
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import scipy.stats as sp\n",
    "from time import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################## \n",
    "# extract MFCC features\n",
    "# STFT : 구간마다 나눔.\n",
    "# 저주파는 촘촘하게, 고주파는 뭉떵그려서 두는 것을 필터 뱅크 에너지라고 함.\n",
    "# MFCC : 소리를 벡터로 나타냄. 각 vector element간의 correlation을 줄이면서 feature들로 표현함\n",
    "def extmfcc(file):\n",
    "    samplerate, d = wavfile.read(file)\n",
    "    #features.append(mfcc(d, nwin=int(samplerate * 0.03), fs=samplerate, nceps= 6)[0])\n",
    "    x = np.float32(d)\n",
    "    hop=samplerate//100\n",
    "    mc = mfcc(y=x, sr=samplerate, n_mfcc=num_mfcc, hop_length=hop, win_length=hop*2)\n",
    "    return np.transpose(mc, (1,0))\n",
    "\n",
    "# Hidden Markove Model(HMM)에서 점프하는 확률을 계산해주는 함수.\n",
    "# Prior : 학습하기 전의 default 값 <-> Posterior : 데이터 분포를 보고서 학습한 값.\n",
    "def initByBakis(inumstates, ibakisLevel):\n",
    "    startprobPrior = np.zeros(inumstates)\n",
    "    startprobPrior[0: ibakisLevel - 1] = 1/float((ibakisLevel - 1))\n",
    "    transmatPrior = getTransmatPrior(inumstates, ibakisLevel)\n",
    "    return startprobPrior, transmatPrior\n",
    "\n",
    "def getTransmatPrior(inumstates, ibakisLevel):\n",
    "    transmatPrior = (1 / float(ibakisLevel)) * np.eye(inumstates)\n",
    "\n",
    "    for i in range(inumstates - (ibakisLevel - 1)):\n",
    "        for j in range(ibakisLevel - 1):\n",
    "            transmatPrior[i, i + j + 1] = 1. / ibakisLevel\n",
    "\n",
    "    for i in range(inumstates - ibakisLevel + 1, inumstates):\n",
    "        for j in range(inumstates - i - j):\n",
    "            transmatPrior[i, i + j] = 1. / (inumstates - i)\n",
    "\n",
    "    return transmatPrior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartProbPrior=\n",
      "[1. 0. 0.]\n",
      "TransMatPrior=\n",
      "[[0.5 0.5 0. ]\n",
      " [0.  0.5 0.5]\n",
      " [0.  0.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "############################################################################################## \n",
    "# hyperparameters - CHANGE THEM TO IMPROVE PERFORMANCE\n",
    "# 1. number of MFCC (feature dimension)\n",
    "num_mfcc = 6\n",
    "#num_mfcc = 10\n",
    "#num_mfcc = 13\n",
    "# 2. Parameters needed to train GMMHMM\n",
    "m_num_of_HMMStates = 3  # number of states\n",
    "m_num_of_mixtures = 2  # number of mixtures for each hidden state\n",
    "m_covarianceType = 'diag'  # covariance type\n",
    "m_n_iter = 10  # number of iterations\n",
    "m_bakisLevel = 2\n",
    "\n",
    "m_startprobPrior, m_transmatPrior = initByBakis(m_num_of_HMMStates,m_bakisLevel)\n",
    "print(\"StartProbPrior=\"); print(m_startprobPrior)\n",
    "print(\"TransMatPrior=\"); print(m_transmatPrior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################## \n",
    "# acoustic model definition\n",
    "class SpeechModel:\n",
    "    def __init__(self,Class,label):\n",
    "        self.traindata = np.zeros((0,num_mfcc))\n",
    "        self.Class = Class\n",
    "        self.label = label\n",
    "        self.model  = hmm.GMMHMM(n_components = m_num_of_HMMStates, n_mix = m_num_of_mixtures, \\\n",
    "                transmat_prior = m_transmatPrior, startprob_prior = m_startprobPrior, \\\n",
    "                covariance_type = m_covarianceType, n_iter = m_n_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_digits(rootpath, speakers, tag, num_trials=10):    \n",
    "    ############################################################################################## \n",
    "    # 1. find files\n",
    "    #    for user \"gjang\", digit 2, recording trial 0 (1st)\n",
    "    #    \"segmented/gjang/2/kdigits0-2.wav\"\n",
    "    # 2. extract MFCC features for training and testing\n",
    "    #    for each digit, indexes 4 and 9 for test, and the rest for training\n",
    "\n",
    "    #fpaths = []\n",
    "    #labels = []\n",
    "    spoken = []\n",
    "    m_trainingsetfeatures = []\n",
    "    m_trainingsetlabels = []\n",
    "\n",
    "    count = 0\n",
    "    for username in speakers:\n",
    "        apath2 = addpath(rootpath, username)    # example: segmented/gjang\n",
    "        for ii in range(10):   #dnum in os.listdir(apath2):\n",
    "            dnum = str(ii)\n",
    "            apath3 = addpath(apath2, dnum)     # example: segmented/gjang/2\n",
    "            if dnum not in spoken:\n",
    "                spoken.append(dnum)\n",
    "            for trial in range(num_trials):\n",
    "                file = addpath(apath3,\"{}{}-{}.wav\".format(tag,trial,dnum))      # segmented/gjang/2/kdigits0-2.wav\n",
    "                mc = extmfcc(file)\n",
    "\n",
    "                # display file names for the first 20 files only\n",
    "                count += 1\n",
    "                if count <= 20:\n",
    "                    print(file, dnum, end=' '); print(mc.shape, end=' ')\n",
    "                elif count == 21:\n",
    "                    print('...'); print('')\n",
    "\n",
    "                m_trainingsetfeatures.append(mc)\n",
    "                m_trainingsetlabels.append(dnum)\n",
    "\n",
    "    print('Words spoken:', spoken)\n",
    "    #print(\"number of labels and features = %d, %d\" % ( len(labels), len(features) ))\n",
    "    #print(\"feature shape = \", end='')\n",
    "    #print(features[0].shape)\n",
    "\n",
    "    ############################################################################################## \n",
    "    ntrain = len(m_trainingsetlabels)\n",
    "\n",
    "    print(\"[training] number of labels and features = %d, %d\" % \n",
    "            ( len(m_trainingsetlabels), len(m_trainingsetfeatures)) )\n",
    "    print ('Loading data completed')\n",
    "\n",
    "    ############################################################################################## \n",
    "    # model initialization\n",
    "    gmmhmmindexdict = {}\n",
    "    index = 0\n",
    "    for word in spoken:\n",
    "        gmmhmmindexdict[word] = index\n",
    "        index = index +1\n",
    "\n",
    "    ############################################################################################## \n",
    "    # training GMMHMM Models \n",
    "    start = time()\n",
    "\n",
    "    speechmodels = [None] * len(spoken)\n",
    "    for key in gmmhmmindexdict:\n",
    "        speechmodels[gmmhmmindexdict[key]] = SpeechModel(gmmhmmindexdict[key],key)\n",
    "\n",
    "    for i in range(0,len(m_trainingsetfeatures)):\n",
    "         for j in range(0,len(speechmodels)):\n",
    "             if int(speechmodels[j].Class) == int(gmmhmmindexdict[m_trainingsetlabels[i]]):\n",
    "                speechmodels[j].traindata = np.concatenate((speechmodels[j].traindata , m_trainingsetfeatures[i]))\n",
    "\n",
    "    for speechmodel in speechmodels:\n",
    "        speechmodel.model.fit(speechmodel.traindata)\n",
    "\n",
    "    print ('Training completed -- {0} GMM-HMM models are built for {0} different types of words'.format(len(spoken)))\n",
    "    print('time elapsed: %.2f seconds' % ( time() - start ))\n",
    "    print (\" \"); print(\" \")\n",
    "    \n",
    "    return speechmodels, gmmhmmindexdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits0-0.wav 0 (88, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits1-0.wav 0 (116, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits2-0.wav 0 (79, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits3-0.wav 0 (86, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits4-0.wav 0 (50, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits5-0.wav 0 (74, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits6-0.wav 0 (112, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits7-0.wav 0 (51, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits8-0.wav 0 (61, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits9-0.wav 0 (66, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits0-1.wav 1 (127, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits1-1.wav 1 (98, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits2-1.wav 1 (76, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits3-1.wav 1 (127, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits4-1.wav 1 (82, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits5-1.wav 1 (81, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits6-1.wav 1 (84, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits7-1.wav 1 (68, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits8-1.wav 1 (63, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits9-1.wav 1 (54, 6) ...\n",
      "\n",
      "Words spoken: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "[training] number of labels and features = 700, 700\n",
      "Loading data completed\n",
      "Training completed -- 10 GMM-HMM models are built for 10 different types of words\n",
      "time elapsed: 75.81 seconds\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "speechmodels, gmmhmmindexdict = train_digits(trainroot, labels_train, 'kdigits', num_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_digits(speechmodels, gmmhmmindexdict, rootpath, speakers, tag, num_trials=10):    \n",
    "\n",
    "    ############################################################################################## \n",
    "    # 1. find files\n",
    "    #    for user \"gjang\", digit 2, recording trial 0 (1st)\n",
    "    #    \"segmented/gjang/2/kdigits0-2.wav\"\n",
    "    # 2. extract MFCC features for training and testing\n",
    "    #    for each digit, indexes 4 and 9 for test, and the rest for training\n",
    "\n",
    "    #fpaths = []\n",
    "    #labels = []\n",
    "    spoken = []\n",
    "    m_features = []\n",
    "    m_labels = []\n",
    "\n",
    "    count = 0\n",
    "    for username in speakers:\n",
    "        apath2 = addpath(rootpath, username)    # example: segmented/gjang\n",
    "        for ii in range(10):   #dnum in os.listdir(apath2):\n",
    "            dnum = str(ii)\n",
    "            apath3 = addpath(apath2, dnum)     # example: segmented/gjang/2\n",
    "            if dnum not in spoken:\n",
    "                spoken.append(dnum)\n",
    "            for trial in range(num_trials):\n",
    "                file = addpath(apath3,\"{}{}-{}.wav\".format(tag,trial,dnum))      # segmented/gjang/2/kdigits0-2.wav\n",
    "                mc = extmfcc(file)\n",
    "\n",
    "                # display file names for the first 20 files only\n",
    "                count += 1\n",
    "                if count <= 20:\n",
    "                    print(file, dnum, end=' '); print(mc.shape, end=' ')\n",
    "                elif count == 21:\n",
    "                    print('...'); print('')\n",
    "\n",
    "                m_features.append(mc)\n",
    "                m_labels.append(dnum)\n",
    "\n",
    "    print('Words spoken:', spoken)\n",
    "    #print(\"number of labels and features = %d, %d\" % ( len(labels), len(features) ))\n",
    "    #print(\"feature shape = \", end='')\n",
    "    #print(features[0].shape)\n",
    "\n",
    "    ############################################################################################## \n",
    "    print(\"[validation] number of labels and features = %d, %d\" % ( len(m_labels), len(m_features)) )\n",
    "    print ('Loading data completed')\n",
    "\n",
    "    ############################################################################################## \n",
    "    # testing\n",
    "    print(\"Prediction started\")\n",
    "    m_PredictionlabelList = []\n",
    "\n",
    "    for i in range(0,len(m_features)):\n",
    "        scores = []\n",
    "        for speechmodel in speechmodels:\n",
    "             scores.append(speechmodel.model.score(m_features[i]))\n",
    "        id  = scores.index(max(scores))\n",
    "        m_PredictionlabelList.append(speechmodels[id].Class)\n",
    "        #print(str(np.round(scores, 3)) + \" \" + str(max(np.round(scores, 3))) +\" \"+\":\"+ speechmodels[id].label)\n",
    "\n",
    "    accuracy = 0.0\n",
    "    count = 0\n",
    "    print(\"\")\n",
    "    print(\"Prediction for Testing DataSet:\")\n",
    "\n",
    "    for i in range(0,len(m_labels)):\n",
    "        #print( \"Label\"+str(i+1)+\":\"+m_labels[i])\n",
    "        if gmmhmmindexdict[m_labels[i]] == m_PredictionlabelList[i]:\n",
    "           count = count+1\n",
    "\n",
    "    accuracy = 100.0*count/float(len(m_labels))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"accuracy =\"+str(accuracy))\n",
    "    print(\"\")\n",
    "\n",
    "    ############################################################################################## \n",
    "    # end of testing\n",
    "    ############################################################################################## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits0-0.wav 0 (88, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits1-0.wav 0 (116, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits2-0.wav 0 (79, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits3-0.wav 0 (86, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits4-0.wav 0 (50, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits5-0.wav 0 (74, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits6-0.wav 0 (112, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits7-0.wav 0 (51, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits8-0.wav 0 (61, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/0/kdigits9-0.wav 0 (66, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits0-1.wav 1 (127, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits1-1.wav 1 (98, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits2-1.wav 1 (76, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits3-1.wav 1 (127, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits4-1.wav 1 (82, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits5-1.wav 1 (81, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits6-1.wav 1 (84, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits7-1.wav 1 (68, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits8-1.wav 1 (63, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-train/segmented-train/11jeonghy/1/kdigits9-1.wav 1 (54, 6) ...\n",
      "\n",
      "Words spoken: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "[validation] number of labels and features = 700, 700\n",
      "Loading data completed\n",
      "Prediction started\n",
      "\n",
      "Prediction for Testing DataSet:\n",
      "\n",
      "accuracy =39.285714285714285\n",
      "\n",
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/0/kdigits0-0.wav 0 (98, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/0/kdigits1-0.wav 0 (105, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/0/kdigits2-0.wav 0 (94, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/0/kdigits3-0.wav 0 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/0/kdigits4-0.wav 0 (100, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/0/kdigits5-0.wav 0 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/0/kdigits6-0.wav 0 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/0/kdigits7-0.wav 0 (90, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/0/kdigits8-0.wav 0 (108, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/0/kdigits9-0.wav 0 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/1/kdigits0-1.wav 1 (121, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/1/kdigits1-1.wav 1 (103, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/1/kdigits2-1.wav 1 (92, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/1/kdigits3-1.wav 1 (101, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/1/kdigits4-1.wav 1 (108, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/1/kdigits5-1.wav 1 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/1/kdigits6-1.wav 1 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/1/kdigits7-1.wav 1 (97, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/1/kdigits8-1.wav 1 (104, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/org/chlee/1/kdigits9-1.wav 1 (91, 6) ...\n",
      "\n",
      "Words spoken: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "[validation] number of labels and features = 300, 300\n",
      "Loading data completed\n",
      "Prediction started\n",
      "\n",
      "Prediction for Testing DataSet:\n",
      "\n",
      "accuracy =32.666666666666664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validation_digits(speechmodels, gmmhmmindexdict, trainroot, labels_train, 'kdigits', num_trials=10)\n",
    "validation_digits(speechmodels, gmmhmmindexdict, valclean, labels_val, 'kdigits', num_trials=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - - - \n",
    "### noise 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/climate/workspace/ssp2023/practice/audio/audio_car.wav (175745,) [-0.01342773 -0.0222168  -0.02905273 ... -0.0390625  -0.03930664\n",
      " -0.04086304]\n",
      "/home/climate/workspace/ssp2023/practice/audio/audio_car_wideband.wav (175745,) [-0.05984497 -0.14807129 -0.14700317 ... -0.10241699 -0.10253906\n",
      " -0.09594727]\n",
      "Fs = 16000, Ns = 160, Nf = 320, NFFT = 512, hNo = 257\n"
     ]
    }
   ],
   "source": [
    "audioinputpath = current_path+'/audio'\n",
    "noisefile  = addpath(audioinputpath, 'audio_car.wav')\n",
    "wnoisefile  = addpath(audioinputpath, 'audio_car_wideband.wav')   # 넓은 주파수 대역에 분포한 잡음\n",
    "\n",
    "Fs=16000\n",
    "noise, _ = librosa.load(noisefile, sr=Fs, mono=True)\n",
    "wnoise, _ = librosa.load(wnoisefile, sr=Fs, mono=True)\n",
    "# sr: target sampling rate. ‘None’ uses the native sampling rate\n",
    "# mono = True: convert signal to mono\n",
    "\n",
    "print(noisefile, noise.shape, noise)\n",
    "print(wnoisefile, wnoise.shape, wnoise)\n",
    "\n",
    "Ns = int(Fs*Ts)    # shift number of samples\n",
    "Nf = int(Fs*Tf)    # frame number of samples\n",
    "NFFT = int(2**(np.ceil(np.log2(Nf))))   # Nf보다 크거나 같은 2의 거듭제곱을 NFFT 로 정의\n",
    "hNo = NFFT//2+1\n",
    "print('Fs = %d, Ns = %d, Nf = %d, NFFT = %d, hNo = %d' % (Fs, Ns, Nf, NFFT, hNo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mixed_signals_2(speech, noise, SNRs, isdraw=False):\n",
    "    std_s = np.sqrt(np.mean(speech**2))\n",
    "    std_n = np.sqrt(np.mean(noise[:len(speech)]**2))\n",
    "    mixedSig = []\n",
    "    for snr in SNRs:\n",
    "        gain = np.power(10, -snr/20)\n",
    "        gn = noise[:len(speech)]/std_n*std_s*gain\n",
    "        m = speech + gn\n",
    "        mixedSig.append(m)\n",
    "\n",
    "    return mixedSig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioroot = valroot\n",
    "audioclean = valclean\n",
    "labels = labels_val\n",
    "noisyroots = [addpath(audioroot,'nbnSNR'), addpath(audioroot,'wbnSNR')]\n",
    "SNRs = [10, 0, -10]\n",
    "\n",
    "for subname in labels:\n",
    "    num_files = 0\n",
    "    for w in range(10):\n",
    "        for trial in range(10):\n",
    "            basename = '%d/kdigits%d-%d.wav'%(w,trial,w)\n",
    "            infile = addpath(audioclean, addpath(subname, basename))            \n",
    "            num_files += 1\n",
    "            \n",
    "            signal, Fs = librosa.load(infile, sr=Fs, mono=True)\n",
    "            nbnsig = generate_mixed_signals_2(signal, noise, SNRs, False)\n",
    "            wbnsig = generate_mixed_signals_2(signal, wnoise, SNRs, False)\n",
    "            noisy = [nbnsig, wbnsig]\n",
    "            \n",
    "            for jj in range(len(noisy)):\n",
    "                for n in range(len(noisy[jj])):\n",
    "                    outfile = addpath('%s%d'%(noisyroots[jj],SNRs[n]), addpath(subname, basename))\n",
    "                    wav.writewav(outfile, Fs, noisy[jj][n], maxval=1.0)\n",
    "\n",
    "outputpaths = []\n",
    "for jj in range(len(noisy)):\n",
    "    for n in range(len(noisy[jj])):\n",
    "        outputpaths.append('%s%d'%(noisyroots[jj],SNRs[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "testing /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10\n",
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/0/kdigits0-0.wav 0 (98, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/0/kdigits1-0.wav 0 (105, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/0/kdigits2-0.wav 0 (94, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/0/kdigits3-0.wav 0 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/0/kdigits4-0.wav 0 (100, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/0/kdigits5-0.wav 0 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/0/kdigits6-0.wav 0 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/0/kdigits7-0.wav 0 (90, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/0/kdigits8-0.wav 0 (108, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/0/kdigits9-0.wav 0 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/1/kdigits0-1.wav 1 (121, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/1/kdigits1-1.wav 1 (103, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/1/kdigits2-1.wav 1 (92, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/1/kdigits3-1.wav 1 (101, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/1/kdigits4-1.wav 1 (108, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/1/kdigits5-1.wav 1 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/1/kdigits6-1.wav 1 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/1/kdigits7-1.wav 1 (97, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/1/kdigits8-1.wav 1 (104, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR10/chlee/1/kdigits9-1.wav 1 (91, 6) ...\n",
      "\n",
      "Words spoken: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "[validation] number of labels and features = 300, 300\n",
      "Loading data completed\n",
      "Prediction started\n",
      "\n",
      "Prediction for Testing DataSet:\n",
      "\n",
      "accuracy =26.333333333333332\n",
      "\n",
      "--------------------------------\n",
      "testing /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0\n",
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/0/kdigits0-0.wav 0 (98, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/0/kdigits1-0.wav 0 (105, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/0/kdigits2-0.wav 0 (94, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/0/kdigits3-0.wav 0 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/0/kdigits4-0.wav 0 (100, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/0/kdigits5-0.wav 0 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/0/kdigits6-0.wav 0 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/0/kdigits7-0.wav 0 (90, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/0/kdigits8-0.wav 0 (108, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/0/kdigits9-0.wav 0 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/1/kdigits0-1.wav 1 (121, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/1/kdigits1-1.wav 1 (103, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/1/kdigits2-1.wav 1 (92, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/1/kdigits3-1.wav 1 (101, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/1/kdigits4-1.wav 1 (108, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/1/kdigits5-1.wav 1 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/1/kdigits6-1.wav 1 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/1/kdigits7-1.wav 1 (97, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/1/kdigits8-1.wav 1 (104, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR0/chlee/1/kdigits9-1.wav 1 (91, 6) ...\n",
      "\n",
      "Words spoken: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "[validation] number of labels and features = 300, 300\n",
      "Loading data completed\n",
      "Prediction started\n",
      "\n",
      "Prediction for Testing DataSet:\n",
      "\n",
      "accuracy =23.0\n",
      "\n",
      "--------------------------------\n",
      "testing /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10\n",
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/0/kdigits0-0.wav 0 (98, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/0/kdigits1-0.wav 0 (105, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/0/kdigits2-0.wav 0 (94, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/0/kdigits3-0.wav 0 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/0/kdigits4-0.wav 0 (100, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/0/kdigits5-0.wav 0 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/0/kdigits6-0.wav 0 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/0/kdigits7-0.wav 0 (90, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/0/kdigits8-0.wav 0 (108, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/0/kdigits9-0.wav 0 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/1/kdigits0-1.wav 1 (121, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/1/kdigits1-1.wav 1 (103, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/1/kdigits2-1.wav 1 (92, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/1/kdigits3-1.wav 1 (101, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/1/kdigits4-1.wav 1 (108, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/1/kdigits5-1.wav 1 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/1/kdigits6-1.wav 1 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/1/kdigits7-1.wav 1 (97, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/1/kdigits8-1.wav 1 (104, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/nbnSNR-10/chlee/1/kdigits9-1.wav 1 (91, 6) ...\n",
      "\n",
      "Words spoken: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "[validation] number of labels and features = 300, 300\n",
      "Loading data completed\n",
      "Prediction started\n",
      "\n",
      "Prediction for Testing DataSet:\n",
      "\n",
      "accuracy =17.0\n",
      "\n",
      "--------------------------------\n",
      "testing /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10\n",
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/0/kdigits0-0.wav 0 (98, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/0/kdigits1-0.wav 0 (105, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/0/kdigits2-0.wav 0 (94, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/0/kdigits3-0.wav 0 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/0/kdigits4-0.wav 0 (100, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/0/kdigits5-0.wav 0 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/0/kdigits6-0.wav 0 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/0/kdigits7-0.wav 0 (90, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/0/kdigits8-0.wav 0 (108, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/0/kdigits9-0.wav 0 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/1/kdigits0-1.wav 1 (121, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/1/kdigits1-1.wav 1 (103, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/1/kdigits2-1.wav 1 (92, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/1/kdigits3-1.wav 1 (101, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/1/kdigits4-1.wav 1 (108, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/1/kdigits5-1.wav 1 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/1/kdigits6-1.wav 1 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/1/kdigits7-1.wav 1 (97, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/1/kdigits8-1.wav 1 (104, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR10/chlee/1/kdigits9-1.wav 1 (91, 6) ...\n",
      "\n",
      "Words spoken: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "[validation] number of labels and features = 300, 300\n",
      "Loading data completed\n",
      "Prediction started\n",
      "\n",
      "Prediction for Testing DataSet:\n",
      "\n",
      "accuracy =21.0\n",
      "\n",
      "--------------------------------\n",
      "testing /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0\n",
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/0/kdigits0-0.wav 0 (98, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/0/kdigits1-0.wav 0 (105, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/0/kdigits2-0.wav 0 (94, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/0/kdigits3-0.wav 0 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/0/kdigits4-0.wav 0 (100, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/0/kdigits5-0.wav 0 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/0/kdigits6-0.wav 0 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/0/kdigits7-0.wav 0 (90, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/0/kdigits8-0.wav 0 (108, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/0/kdigits9-0.wav 0 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/1/kdigits0-1.wav 1 (121, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/1/kdigits1-1.wav 1 (103, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/1/kdigits2-1.wav 1 (92, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/1/kdigits3-1.wav 1 (101, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/1/kdigits4-1.wav 1 (108, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/1/kdigits5-1.wav 1 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/1/kdigits6-1.wav 1 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/1/kdigits7-1.wav 1 (97, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/1/kdigits8-1.wav 1 (104, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR0/chlee/1/kdigits9-1.wav 1 (91, 6) ...\n",
      "\n",
      "Words spoken: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "[validation] number of labels and features = 300, 300\n",
      "Loading data completed\n",
      "Prediction started\n",
      "\n",
      "Prediction for Testing DataSet:\n",
      "\n",
      "accuracy =10.333333333333334\n",
      "\n",
      "--------------------------------\n",
      "testing /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10\n",
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/0/kdigits0-0.wav 0 (98, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/0/kdigits1-0.wav 0 (105, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/0/kdigits2-0.wav 0 (94, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/0/kdigits3-0.wav 0 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/0/kdigits4-0.wav 0 (100, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/0/kdigits5-0.wav 0 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/0/kdigits6-0.wav 0 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/0/kdigits7-0.wav 0 (90, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/0/kdigits8-0.wav 0 (108, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/0/kdigits9-0.wav 0 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/1/kdigits0-1.wav 1 (121, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/1/kdigits1-1.wav 1 (103, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/1/kdigits2-1.wav 1 (92, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/1/kdigits3-1.wav 1 (101, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/1/kdigits4-1.wav 1 (108, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/1/kdigits5-1.wav 1 (95, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/1/kdigits6-1.wav 1 (96, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/1/kdigits7-1.wav 1 (97, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/1/kdigits8-1.wav 1 (104, 6) /home/climate/workspace/ssp2023/practice/audio/segmented_all/segmented-val/wbnSNR-10/chlee/1/kdigits9-1.wav 1 (91, 6) ...\n",
      "\n",
      "Words spoken: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "[validation] number of labels and features = 300, 300\n",
      "Loading data completed\n",
      "Prediction started\n",
      "\n",
      "Prediction for Testing DataSet:\n",
      "\n",
      "accuracy =11.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Nosie model Test\n",
    "for path in outputpaths:\n",
    "    print('--------------------------------')\n",
    "    print('testing', path)\n",
    "    validation_digits(speechmodels, gmmhmmindexdict, path, labels, 'kdigits', num_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/unsegmented-test/gjang/kdigits0.wav\n",
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/unsegmented-test/gjang/kdigits1.wav\n",
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/unsegmented-test/gjang/kdigits2.wav\n",
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/unsegmented-test/gjang/kdigits3.wav\n",
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/unsegmented-test/gjang/kdigits4.wav\n",
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/unsegmented-test/gjang/kdigits5.wav\n",
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/unsegmented-test/gjang/kdigits6.wav\n",
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/unsegmented-test/gjang/kdigits7.wav\n",
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/unsegmented-test/gjang/kdigits8.wav\n",
      "/home/climate/workspace/ssp2023/practice/audio/segmented_all/unsegmented-test/gjang/kdigits9.wav\n"
     ]
    }
   ],
   "source": [
    "audioroot = current_path+'/audio/segmented_all/unsegmented-test'\n",
    "# audioclean = addpath(audioroot,'org')\n",
    "labels = ['gjang']\n",
    "noisyroots = [addpath(audioroot,'nbnSNR'), addpath(audioroot,'wbnSNR')]\n",
    "SNRs = [10, 0, -10]\n",
    "\n",
    "for subname in labels:\n",
    "    num_files = 0\n",
    "    for trial in range(10):\n",
    "        basename = 'kdigits%d.wav' % (trial)\n",
    "        # infile = addpath(audioclean, addpath(subname, basename))\n",
    "        infile = addpath(audioroot, addpath(subname, basename))\n",
    "        \n",
    "        print(infile)\n",
    "        num_files += 1\n",
    "\n",
    "        signal, Fs = librosa.load(infile, sr=Fs, mono=True)\n",
    "        nbnsig = generate_mixed_signals_2(signal, np.concatenate((noise,noise,noise)), SNRs, False)\n",
    "        wbnsig = generate_mixed_signals_2(signal, np.concatenate((wnoise,wnoise,wnoise)), SNRs, False)\n",
    "        noisy = [nbnsig, wbnsig]\n",
    "\n",
    "        for jj in range(len(noisy)):\n",
    "            for n in range(len(noisy[jj])):\n",
    "                outfile = addpath('%s%d'%(noisyroots[jj],SNRs[n]), addpath(subname, basename))\n",
    "                wav.writewav(outfile, Fs, noisy[jj][n], maxval=1.0)\n",
    "\n",
    "outputpaths = []\n",
    "for jj in range(len(noisy)):\n",
    "    for n in range(len(noisy[jj])):\n",
    "        outputpaths.append('%s%d'%(noisyroots[jj],SNRs[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
